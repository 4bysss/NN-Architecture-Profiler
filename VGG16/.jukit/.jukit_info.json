{"cmd": "import torch\nfrom torch import nn\nfrom torch.nn.modules import MaxPool2d, padding\nfrom torch.utils.data import DataLoader, dataloader, dataset\n\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor, Compose\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation\n\nfrom helper_functions import accuracy_fn\nfrom train_and_eval import test_loop, train_loop\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\ntransformation = Compose([\n    ToTensor(),\n    RandomRotation(degrees=20),\n    RandomHorizontalFlip()\n])\n\n\ntrain_data = datasets.CIFAR100(\n    root=\"dataset\",\n    train=True,\n    transform=transformation,\n    target_transform=None,\n    download=True\n)\n\ntest_data = datasets.CIFAR100(\n    root=\"dataset\",\n    train=False,\n    transform=ToTensor(),\n    target_transform=None,\n    download=True\n)\n\nBATCH_SIZE = 32\n\ntrain_data_loader = DataLoader(\n    dataset=train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\ntest_data_loader = DataLoader(\n    dataset=test_data,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\n\nclass Vgg_16(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        self.layer_1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=3,\n                out_channels=16,\n                kernel_size=2,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(\n                num_features=16\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=2,\n                stride=2,\n                padding=0\n            )\n        )\n        self.layer_2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=1,\n                stride=1,\n                padding=0\n            ),\n            nn.BatchNorm2d(\n                num_features=32\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=2,\n                stride=2,\n                padding=0\n            )\n        )\n        self.layer_3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=2,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(\n                num_features=64\n            ),\n            nn.ReLU(),\n\n            nn.MaxPool2d(\n                kernel_size=2,\n                stride=2,\n                padding=0\n            )\n        )\n        self.layer_4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=64,\n                out_channels=128,\n                kernel_size=2,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(\n                num_features=128\n            ),\n            nn.ReLU(),\n\n            nn.MaxPool2d(\n                kernel_size=2,\n                stride=2,\n                padding=0\n            )\n        )\n\n        self.layer_5 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=128,\n                out_channels=256,\n                kernel_size=2,\n                stride=1,\n                padding=1\n            ),\n            nn.BatchNorm2d(\n                num_features=256\n            ),\n            nn.ReLU(),\n\n            nn.MaxPool2d(\n                kernel_size=2,\n                stride=2,\n                padding=0\n            )\n        )\n\n        self.layer_6 = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(\n                in_features=256,\n                out_features=1024\n            ),\n            nn.Dropout(p=0.5),\n            nn.ReLU(),\n            nn.Linear(\n                in_features=1024,\n                out_features=100\n            ),\n        )\n\n    def forward(self, X):\n\n        out = self.layer_1(X)\n        out = self.layer_2(out)\n        out = self.layer_3(out)\n        out = self.layer_4(out)\n        out = self.layer_5(out)\n        out = self.layer_6(out)\n        return out\nfoo = torch.rand(4, 3, 32 ,32)\n\nmodel = Vgg_16()\nfoo = model.layer_1(foo)\nfoo.shape\nfoo = model.layer_2(foo)\nfoo.shape\nfoo = model.layer_3(foo)\nfoo.shape\nfoo = model.layer_4(foo)\nfoo.shape\nfoo = model.layer_5(foo)\nfoo.shape\nfoo = model.layer_6(foo)\nfoo.shape\nlossF = nn.CrossEntropyLoss()\noptim = torch.optim.Adam(\n    params=model.parameters(),\n    lr=0.001\n)\n'''\ntrain_loop(\n    model=model,\n    lossF=lossF,\n    optim=optim,\n    trainDLoader=train_data_loader,\n    epochs=10,\n    accuracy_fn=accuracy_fn,\n    device=device\n)\ntest_loop(\n    model=model,\n    lossF=lossF,\n    testDLoader=test_data_loader,\n    accuracy_fn=accuracy_fn,\n    device=device\n)\n'''\n", "cmd_opts": " --cell_id=NONE -s", "import_complete": 1, "terminal": "nvimterm"}