{"cmd": "import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n\nfrom torchvision import datasets\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation, ToTensor, Compose, Resize\n\nfrom helper_functions import accuracy_fn\nfrom train_and_eval import train_loop, test_loop\n\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntransformation_train = Compose([\n    Resize((224, 224)),\n    ToTensor(),\n    RandomRotation(degrees=20),\n    RandomHorizontalFlip()\n\n])\n\ntransformation_test = Compose([\n    Resize((224, 224)),\n    ToTensor(),\n\n])\n\ntrain_data = datasets.OxfordIIITPet(\n    root=\"dataset\",\n    split=\"trainval\",\n    transform=transformation_train,\n    target_transform=None,\n    download=True,\n)\n\ntest_data = datasets.OxfordIIITPet(\n    root=\"dataset\",\n    split=\"test\",\n    transform=transformation_test,\n    target_transform=None,\n    download=True\n)\n\nBATCH_SIZE = 32\n\ntrain_data_loader = DataLoader(\n    dataset=train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\ntest_data_loader = DataLoader(\n    dataset=test_data,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\n\nclass Vgg16_imageNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=3,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=64,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=3,\n                stride=2,\n                padding=1\n            ),\n\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=64,\n                out_channels=128,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=128,\n                out_channels=128,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=3,\n                stride=2,\n                padding=1\n            ),\n\n        )\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=128,\n                out_channels=256,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=256,\n                out_channels=256,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=256,\n                out_channels=256,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=3,\n                stride=2,\n                padding=1\n            ),\n        )\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=256,\n                out_channels=512,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=512,\n                out_channels=512,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=512,\n                out_channels=512,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=3,\n                stride=2,\n                padding=1\n            ),\n        )\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=512,\n                out_channels=512,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=512,\n                out_channels=512,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.Conv2d(\n                in_channels=512,\n                out_channels=512,\n                kernel_size=3,\n                stride=1,\n                padding=1,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=3,\n                stride=2,\n                padding=1\n            ),\n\n        )\n        self.FullLayer = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(\n                in_features=512*7*7,\n                out_features=4096,\n            ),\n            nn.ReLU(),\n            nn.Linear(\n                in_features=4096,\n                out_features=4096,\n            ),\n            nn.ReLU(),\n            nn.Linear(\n                in_features=4096,\n                out_features=37,\n            )\n        )\n\n    def forward(self, X):\n        out = self.layer1(X)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        return self.FullLayer(out)\n\n\nmodel = Vgg16_imageNet()\n\nfoo = torch.rand(1, 3, 224, 224)\nfoo = model.layer1(foo)\nfoo.shape\nfoo = model.layer2(foo)\nfoo.shape\nfoo = model.layer3(foo)\nfoo.shape\nfoo = model.layer4(foo)\nfoo.shape\nfoo = model.layer5(foo)\nfoo.shape\nfoo = model.FullLayer(foo)\nfoo.shape\n\noptim = torch.optim.Adam(\n    params=model.parameters(),\n    lr=0.01,\n)\n\nlossF = nn.CrossEntropyLoss()\n\ntrain_loop(\n    model=model,\n    lossF=lossF,\n    optim=optim,\n    trainDLoader=train_data_loader,\n    epochs=1,\n    accuracy_fn=accuracy_fn,\n    device=device\n)\ntest_loop(\n    model=model,\n    lossF=lossF,\n    testDLoader=test_data_loader,\n    accuracy_fn=accuracy_fn,\n    device=device\n)", "cmd_opts": " --cell_id=NONE -s", "import_complete": 1, "terminal": "nvimterm"}